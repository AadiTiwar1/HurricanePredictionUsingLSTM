{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0df95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f27930",
   "metadata": {},
   "source": [
    "First, we read in the data, dropping the index and the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfabee6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      basin     name  year  cyclone_of_the_year  num_of_track_entries  \\\n",
      "0        AL  UNNAMED  1851                    1                    14   \n",
      "1        AL  UNNAMED  1851                    1                    14   \n",
      "2        AL  UNNAMED  1851                    1                    14   \n",
      "3        AL  UNNAMED  1851                    1                    14   \n",
      "4        AL  UNNAMED  1851                    1                    14   \n",
      "...     ...      ...   ...                  ...                   ...   \n",
      "49100    AL     KATE  2015                   12                    20   \n",
      "49101    AL     KATE  2015                   12                    20   \n",
      "49102    AL     KATE  2015                   12                    20   \n",
      "49103    AL     KATE  2015                   12                    20   \n",
      "49104    AL     KATE  2015                   12                    20   \n",
      "\n",
      "           date  time record_identifier status_of_system latitude  ...  \\\n",
      "0      18510625     0               NaN               HU    28.0N  ...   \n",
      "1      18510625   600               NaN               HU    28.0N  ...   \n",
      "2      18510625  1200               NaN               HU    28.0N  ...   \n",
      "3      18510625  1800               NaN               HU    28.1N  ...   \n",
      "4      18510625  2100                 L               HU    28.2N  ...   \n",
      "...         ...   ...               ...              ...      ...  ...   \n",
      "49100  20151112  1200               NaN               EX    41.3N  ...   \n",
      "49101  20151112  1800               NaN               EX    41.9N  ...   \n",
      "49102  20151113     0               NaN               EX    41.5N  ...   \n",
      "49103  20151113   600               NaN               EX    40.8N  ...   \n",
      "49104  20151113  1200               NaN               EX    40.7N  ...   \n",
      "\n",
      "      34kt_SW  34kt_NW  50kt_NE  50kt_SE  50kt_SW  50kt_NW  64kt_NE  64kt_SE  \\\n",
      "0         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "1         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "3         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "49100   180.0    120.0    120.0    120.0     60.0      0.0      0.0      0.0   \n",
      "49101   180.0    120.0    120.0    120.0     60.0      0.0      0.0      0.0   \n",
      "49102   200.0    220.0    120.0    120.0     60.0      0.0      0.0      0.0   \n",
      "49103   180.0    220.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "49104   150.0    220.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "       64kt_SW  64kt_NW  \n",
      "0          NaN      NaN  \n",
      "1          NaN      NaN  \n",
      "2          NaN      NaN  \n",
      "3          NaN      NaN  \n",
      "4          NaN      NaN  \n",
      "...        ...      ...  \n",
      "49100      0.0      0.0  \n",
      "49101      0.0      0.0  \n",
      "49102      0.0      0.0  \n",
      "49103      0.0      0.0  \n",
      "49104      0.0      0.0  \n",
      "\n",
      "[49105 rows x 25 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>max_sustained_wind</th>\n",
       "      <th>central_pressure</th>\n",
       "      <th>next_windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18510625.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18510625.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18510625.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18510625.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18510625.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49100</th>\n",
       "      <td>20151112.0</td>\n",
       "      <td>41.3</td>\n",
       "      <td>-50.4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>981.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49101</th>\n",
       "      <td>20151112.0</td>\n",
       "      <td>41.9</td>\n",
       "      <td>-49.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49102</th>\n",
       "      <td>20151113.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>-49.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49103</th>\n",
       "      <td>20151113.0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>-47.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>985.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49104</th>\n",
       "      <td>20151113.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-45.4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>987.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49105 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  latitude  longitude  max_sustained_wind  central_pressure  \\\n",
       "0      18510625.0      28.0      -94.8                80.0             961.0   \n",
       "1      18510625.0      28.0      -95.4                80.0             961.0   \n",
       "2      18510625.0      28.0      -96.0                80.0             961.0   \n",
       "3      18510625.0      28.1      -96.5                80.0             961.0   \n",
       "4      18510625.0      28.2      -96.8                80.0             961.0   \n",
       "...           ...       ...        ...                 ...               ...   \n",
       "49100  20151112.0      41.3      -50.4                55.0             981.0   \n",
       "49101  20151112.0      41.9      -49.9                55.0             983.0   \n",
       "49102  20151113.0      41.5      -49.2                50.0             985.0   \n",
       "49103  20151113.0      40.8      -47.5                45.0             985.0   \n",
       "49104  20151113.0      40.7      -45.4                45.0             987.0   \n",
       "\n",
       "       next_windspeed  \n",
       "0                80.0  \n",
       "1                80.0  \n",
       "2                80.0  \n",
       "3                80.0  \n",
       "4                70.0  \n",
       "...               ...  \n",
       "49100            55.0  \n",
       "49101            50.0  \n",
       "49102            45.0  \n",
       "49103            45.0  \n",
       "49104            45.0  \n",
       "\n",
       "[49105 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_lat_long(value):\n",
    "    if value[-1] == 'S' or value[-1] == 'W':\n",
    "        return -1 * float(value[:-1])\n",
    "    else:\n",
    "        return float(value[:-1])\n",
    "\n",
    "df = pd.read_csv('../static/dataset/atlantic.csv', sep=',', index_col=False)\n",
    "\n",
    "df.drop([\"basin\", \"name\", \"year\", \"cyclone_of_the_year\", \"num_of_track_entries\",\n",
    "    \"time\", \"record_identifier\", \"status_of_system\", \"34kt_NE\",\n",
    "    \"34kt_SE\",\"34kt_SW\",\"34kt_NW\",\"50kt_NE\",\"50kt_SE\",\"50kt_SW\",\n",
    "    \"50kt_NW\",\"64kt_NE\",\"64kt_SE\",\"64kt_SW\",\"64kt_NW\"], inplace=True, axis=1)\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format = \"%Y%m%d\").dt.strftime('%Y-%m-%d')\n",
    "df['next_windspeed'] =  df['max_sustained_wind'].shift(-1)\n",
    "df['date'] = df['date'].apply(lambda x: float(x.split()[0].replace('-', '')))\n",
    "\n",
    "df['latitude'] = df['latitude'].map(lambda x: convert_lat_long(x))\n",
    "df['longitude'] = df['longitude'].map(lambda x: convert_lat_long(x))\n",
    "\n",
    "df['max_sustained_wind'] = df['max_sustained_wind'].replace(-99, np.nan)\n",
    "df['next_windspeed'] = df['next_windspeed'].replace(-99, np.nan)\n",
    "\n",
    "df['max_sustained_wind'] =  df['max_sustained_wind'].fillna(method='ffill', limit=1000)\n",
    "df['max_sustained_wind'] =  df['max_sustained_wind'].fillna(method='bfill', limit=1000)\n",
    "df['central_pressure'] = df['central_pressure'].fillna(method='ffill', limit=1000)\n",
    "df['central_pressure'] = df['central_pressure'].fillna(method='bfill', limit=1000)\n",
    "df['next_windspeed'] = df['next_windspeed'].fillna(method='ffill', limit=1000)\n",
    "df['next_windspeed'] = df['next_windspeed'].fillna(method='bfill', limit=1000)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c9d98",
   "metadata": {},
   "source": [
    "We identify the dependent and independent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dae266cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"next_windspeed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cab92ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['central_pressure', 'date', 'latitude', 'longitude', 'max_sustained_wind']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(df.columns.difference([target]))\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c729ea8",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a0464",
   "metadata": {},
   "source": [
    "To process the data, we first split it into training and test data, where two-thirds of the data is used for training, and the last third is used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb5a704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = int(len(df) * 0.8)\n",
    "\n",
    "df_train = df.loc[:size].copy()\n",
    "df_test = df.loc[size:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3fa0e",
   "metadata": {},
   "source": [
    "Next, in order to ensure that some values due to their mangnitude do not inherently dominate the features, we standardize their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "761b00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = df_train[target].mean()\n",
    "target_stdev = df_train[target].std()\n",
    "\n",
    "for c in df_train.columns:\n",
    "    mean = df_train[c].mean()\n",
    "    stdev = df_train[c].std()\n",
    "\n",
    "    df_train[c] = (df_train[c] - mean) / stdev\n",
    "    df_test[c] = (df_test[c] - mean) / stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aafb4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Factory import SequenceDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fdce3",
   "metadata": {},
   "source": [
    "Finally, the last step in the data processing to prepare for LSTM is to prepare the data in a sequence of past observations. Preparation of the LSTM on time series data means that it uses a certain number of past observations to predict the future. In this case, the sequence length decides how many days the LSTM considers in advance. If the sequence length is $n$, then the LSTM considers the last $n$ observations to predict the $n+1$th day.\n",
    "\n",
    "We decided the sequence length as 3 for purposes of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3c10d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([1, 6, 5])\n",
      "Target shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(345089723)\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 6\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2c27d",
   "metadata": {},
   "source": [
    "# Classical LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a7af8",
   "metadata": {},
   "source": [
    "We first define two functions:\n",
    "    \n",
    "- train_model: function to train the model based on the batches of data\n",
    "- test_model: function to test the model on the testing data\n",
    "    \n",
    "We print the loss at the end to understand how the model is performing with regards to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d32cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af0713",
   "metadata": {},
   "source": [
    "## Running the Classical LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996cbb1",
   "metadata": {},
   "source": [
    "To understand our implementation of QLSTM, we first explain our implementation LSTM. LSTM follows the following structure:\n",
    "\n",
    "<img src=\"lstm2.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Image taken from: Quantum Long Short-Term Memory, https://arxiv.org/pdf/2009.01783.pdf (Samuel Yen-Chi Chen, Shinjae Yoo, and Yao-Lung L. Fang (2020)) \n",
    "\n",
    "Simply put, LSTM uses 4 neural network layers in each LSTM cell. They are:\n",
    "\n",
    "- Forget layer\n",
    "- Input layer\n",
    "- Update layer\n",
    "- Output layer\n",
    "\n",
    "We can see the corresponding layers in the W cells in the picture above. We will be skipping the technical details, but it is important to note that these 4 layers are the keys to building an LSTM neural network model that we can train and eventually use to predict. They usually take the form of a normal NN layer (like a linear layer with reLU or convolutional layers).\n",
    "\n",
    "LSTMs are well studied, and there is a native implementation of it in PyTorch to begin with, so we use a slightly modified version of it for the time series LSTM that we perform here. The code for the time series LSTM was reused from:\n",
    "\n",
    "How to use PyTorch LSTMs for time series regression: https://www.crosstab.io/articles/time-series-pytorch-lstm, Brian Kent.\n",
    "\n",
    "In the following code, we train LSTM to predict future stock prices, and then test it on the test dataset. The learning rate of 0.0001 was decided after some experimentation, where we chose the learning rate that gave accurate results. The number of epochs we use is 20, by which it would have converged and thus would suffice for the purposes of this notebook. After that, we visualize three different graphs: the comparison between the real stock prices and the ones given by the model; and the evolution of test loss and training loss by epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d03ead84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Factory import ShallowRegressionLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a8b6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "num_hidden_units = 16\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=len(features), hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "489e5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 1.1574630414344378\n",
      "\n",
      "Epoch 0\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "classical_loss_train = []\n",
    "classical_loss_test = []\n",
    "print(\"Untrained test\\n--------\")\n",
    "test_loss = test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "classical_loss_test.append(test_loss)\n",
    "\n",
    "for ix_epoch in range(6):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    print()\n",
    "    classical_loss_train.append(train_loss)\n",
    "    classical_loss_test.append(test_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78f701",
   "metadata": {},
   "source": [
    "We then use the model to predict the test set, and then compare the results of the prediction to the real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ffa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58531cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col = \"Model Forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "for c in df_out.columns:\n",
    "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
    "\n",
    "accuracy = (1 - (np.sum(np.absolute(df_out[\"next_windspeed\"] - df_out[\"Model Forecast\"])) / np.sum(df_out[\"next_windspeed\"]))) * 100\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ed8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(range(len(df_out)), df_out[\"next_windspeed\"], label = \"Real\")\n",
    "plt.plot(range(len(df_out)), df_out[\"Model Forecast\"], label = \"LSTM Prediction\")\n",
    "plt.ylabel('Wind Speed')\n",
    "plt.xlabel('Days')\n",
    "plt.vlines(size, ymin = 30, ymax = 90, label = \"Test set start\", linestyles = \"dashed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(len(classical_loss_test)), classical_loss_test)\n",
    "plt.ylabel('Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(len(classical_loss_train)), classical_loss_train)\n",
    "plt.ylabel('Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
